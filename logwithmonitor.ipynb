{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-51a951dc3f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m## 调用函数执行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-51a951dc3f8d>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIRIS_TRAINNING\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtarget_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mfeatures_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\sf\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py\u001b[0m in \u001b[0;36mload_csv_with_header\u001b[1;34m(filename, target_dtype, features_dtype, target_column)\u001b[0m\n\u001b[0;32m     45\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdata_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import  absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IRIS_TRAINNING=os.path.join(os.path.dirname('.'),'iris_trainning.csv')\n",
    "IRIS_TEST=os.path.join(os.path.dirname('.'),'iris_test.csv')\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_set=tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TRAINNING,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    test_set=tf.contrib.learn.datasets.base.load_csv_width_header(\n",
    "        filename=IRIS_TEST,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    # 添加日志信息\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    \n",
    "    #为代码增加监视器,并使用MetricSpec定制评估标准\n",
    "    \n",
    "    validation_metrics={\n",
    "        \"accuracy\":\n",
    "            tf.contrib.learn.MetricSpec(\n",
    "                metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "                prediction_key=tf.contrib.learn.prediction_key.PredictionKey.CLASSES\n",
    "            ),\n",
    "        \"precision\":tf.contrib.learn.MetricSpec(\n",
    "            metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "            prediction_key=tf.contrib.learn.prediction_key.PredictionKey.CLASSES\n",
    "        ),\n",
    "        \"recall\":\n",
    "            metric_fn=tf.contrib.learn.MetricSpec(\n",
    "                metric_fn=tf.contrib.metrics.streaming_recall,\n",
    "                prediction_key=tf.contrib.learn.prediction_key.PredictionKey.CLASSES\n",
    "            )  \n",
    "    }\n",
    "    \n",
    "    validation_monitor=tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        test_set.data,\n",
    "        test_set.target,\n",
    "        every_n_steps=50,\n",
    "        metrics=validation_metrics\n",
    "    )\n",
    "    \n",
    "    \n",
    "    feature_columns=[tf.contrib.layers.real_valued_column(\"\",dimension=4)]\n",
    "    classifier=tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10,20,10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir='temp1/iris_model.txt',\n",
    "                                              config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1)\n",
    "                                             )\n",
    "    \n",
    "    \n",
    "    #训练模型\n",
    "    classifier.fit(x=trainning_set.data,\n",
    "                  y=trainning_set.target,\n",
    "                  steps=2000,\n",
    "                  monitors=[validation_monitor])\n",
    "    \n",
    "    # 执行测试集\n",
    "    accuracy_score=classifier.evaluate(x=test_set.data,\n",
    "                       y=test.target)['accuracy']\n",
    "    \n",
    "    \n",
    "    print_function(\"Accuracy is:{0:f}\".format(accuracy_score))\n",
    "    \n",
    "    # 构造新的数据集，预测新的函数\n",
    "    \n",
    "    new_samples=np.array([\n",
    "        [6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]\n",
    "    ],dtype=float)\n",
    "    \n",
    "    y=classifier.predict(new_samples,as_iterable=True)\n",
    "    \n",
    "    print('Predictions:{}'.format(str(y)))\n",
    "    \n",
    "    \n",
    "\n",
    "## 调用函数执行\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
